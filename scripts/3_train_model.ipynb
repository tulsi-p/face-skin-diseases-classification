{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1yjdvCiER_newMwNlcNHTDYM86NyK3Uhd","authorship_tag":"ABX9TyP9K5/rfptIdMuTL/vKzDcx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"s8VdDN65shhj","executionInfo":{"status":"ok","timestamp":1743915649986,"user_tz":-330,"elapsed":29198642,"user":{"displayName":"345_TULSI PANIGRAHY","userId":"01470649530670878491"}},"outputId":"e123b81d-4f31-4e5b-e3e2-8d12dc09d909"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 30 Complete [00h 43m 17s]\n","val_accuracy: 0.46875\n","\n","Best val_accuracy So Far: 0.65625\n","Total elapsed time: 05h 31m 26s\n","Best hyperparameters: {'base_model': 'MobileNetV2', 'trainable_base': False, 'dense_units': 512, 'dense_activation': 'relu', 'dropout_rate': 0.4, 'learning_rate': 0.00014002116550133282, 'tuner/epochs': 15, 'tuner/initial_epoch': 5, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0012'}\n","Best model architecture:\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ mobilenetv2_1.00_224 (Functional)    │ (None, 7, 7, 1280)          │       2,257,984 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ global_average_pooling2d_1           │ (None, 1280)                │               0 │\n","│ (GlobalAveragePooling2D)             │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_2 (Dense)                      │ (None, 512)                 │         655,872 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_1                │ (None, 512)                 │           2,048 │\n","│ (BatchNormalization)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (Dropout)                  │ (None, 512)                 │               0 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (Dense)                      │ (None, 5)                   │           2,565 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"," Total params: 2,918,469 (11.13 MB)\n"," Trainable params: 659,461 (2.52 MB)\n"," Non-trainable params: 2,259,008 (8.62 MB)\n","\n","Training the best model...\n","Epoch 1/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2366 - auc: 0.5561 - loss: 2.2708 - precision: 0.2241 - recall: 0.1503"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 0.2393 - auc: 0.5587 - loss: 2.2610 - precision: 0.2277 - recall: 0.1529 - val_accuracy: 0.3839 - val_auc: 0.7171 - val_loss: 1.4277 - val_precision: 0.5484 - val_recall: 0.1518 - learning_rate: 1.4002e-04\n","Epoch 2/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 573ms/step - accuracy: 0.3125 - auc: 0.6398 - loss: 1.9980 - precision: 0.3182 - recall: 0.2188 - val_accuracy: 0.3705 - val_auc: 0.7190 - val_loss: 1.4222 - val_precision: 0.5806 - val_recall: 0.1607 - learning_rate: 1.4002e-04\n","Epoch 3/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4993 - auc: 0.7928 - loss: 1.3877 - precision: 0.5411 - recall: 0.4158"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.4994 - auc: 0.7931 - loss: 1.3870 - precision: 0.5412 - recall: 0.4159 - val_accuracy: 0.4821 - val_auc: 0.7893 - val_loss: 1.2570 - val_precision: 0.6768 - val_recall: 0.2991 - learning_rate: 1.4002e-04\n","Epoch 4/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 523ms/step - accuracy: 0.3125 - auc: 0.6819 - loss: 1.9448 - precision: 0.3200 - recall: 0.2500 - val_accuracy: 0.4777 - val_auc: 0.7890 - val_loss: 1.2593 - val_precision: 0.6735 - val_recall: 0.2946 - learning_rate: 1.4002e-04\n","Epoch 5/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5472 - auc: 0.8198 - loss: 1.2850 - precision: 0.5922 - recall: 0.4711"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - accuracy: 0.5475 - auc: 0.8203 - loss: 1.2829 - precision: 0.5926 - recall: 0.4712 - val_accuracy: 0.5848 - val_auc: 0.8244 - val_loss: 1.1643 - val_precision: 0.7391 - val_recall: 0.3795 - learning_rate: 1.4002e-04\n","Epoch 6/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 504ms/step - accuracy: 0.5000 - auc: 0.8746 - loss: 1.0150 - precision: 0.6400 - recall: 0.5000 - val_accuracy: 0.5804 - val_auc: 0.8261 - val_loss: 1.1595 - val_precision: 0.7414 - val_recall: 0.3839 - learning_rate: 1.4002e-04\n","Epoch 7/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5862 - auc: 0.8672 - loss: 1.0686 - precision: 0.6448 - recall: 0.5178"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.5868 - auc: 0.8674 - loss: 1.0679 - precision: 0.6452 - recall: 0.5184 - val_accuracy: 0.5893 - val_auc: 0.8428 - val_loss: 1.1037 - val_precision: 0.7206 - val_recall: 0.4375 - learning_rate: 1.4002e-04\n","Epoch 8/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 546ms/step - accuracy: 0.7188 - auc: 0.8844 - loss: 0.9657 - precision: 0.7500 - recall: 0.6562 - val_accuracy: 0.5893 - val_auc: 0.8431 - val_loss: 1.1033 - val_precision: 0.7299 - val_recall: 0.4464 - learning_rate: 1.4002e-04\n","Epoch 9/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.6167 - auc: 0.8738 - loss: 1.0525 - precision: 0.6601 - recall: 0.5568 - val_accuracy: 0.5893 - val_auc: 0.8533 - val_loss: 1.0747 - val_precision: 0.6986 - val_recall: 0.4554 - learning_rate: 1.4002e-04\n","Epoch 10/30\n","\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.6562 - auc: 0.9109 - loss: 0.8410 - precision: 0.8182 - recall: 0.5625"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 614ms/step - accuracy: 0.6562 - auc: 0.9109 - loss: 0.8410 - precision: 0.8182 - recall: 0.5625 - val_accuracy: 0.5938 - val_auc: 0.8545 - val_loss: 1.0716 - val_precision: 0.6939 - val_recall: 0.4554 - learning_rate: 1.4002e-04\n","Epoch 11/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6831 - auc: 0.9169 - loss: 0.8245 - precision: 0.7263 - recall: 0.6286"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.6825 - auc: 0.9167 - loss: 0.8254 - precision: 0.7258 - recall: 0.6281 - val_accuracy: 0.6116 - val_auc: 0.8614 - val_loss: 1.0597 - val_precision: 0.6807 - val_recall: 0.5045 - learning_rate: 1.4002e-04\n","Epoch 12/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 341ms/step - accuracy: 0.6250 - auc: 0.9449 - loss: 0.6906 - precision: 0.7692 - recall: 0.6250 - val_accuracy: 0.6071 - val_auc: 0.8598 - val_loss: 1.0667 - val_precision: 0.6726 - val_recall: 0.5045 - learning_rate: 1.4002e-04\n","Epoch 13/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6678 - auc: 0.9075 - loss: 0.8641 - precision: 0.7284 - recall: 0.6200"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.6679 - auc: 0.9076 - loss: 0.8640 - precision: 0.7286 - recall: 0.6200 - val_accuracy: 0.6250 - val_auc: 0.8578 - val_loss: 1.0932 - val_precision: 0.6590 - val_recall: 0.5089 - learning_rate: 1.4002e-04\n","Epoch 14/30\n","\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.7188 - auc: 0.9374 - loss: 0.6969 - precision: 0.7586 - recall: 0.6875"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 379ms/step - accuracy: 0.7188 - auc: 0.9374 - loss: 0.6969 - precision: 0.7586 - recall: 0.6875 - val_accuracy: 0.6295 - val_auc: 0.8573 - val_loss: 1.0949 - val_precision: 0.6590 - val_recall: 0.5089 - learning_rate: 1.4002e-04\n","Epoch 15/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.6559 - auc: 0.9105 - loss: 0.8537 - precision: 0.6896 - recall: 0.5886 - val_accuracy: 0.6295 - val_auc: 0.8589 - val_loss: 1.0941 - val_precision: 0.6704 - val_recall: 0.5357 - learning_rate: 7.0011e-05\n","Epoch 16/30\n","\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 2s/step - accuracy: 0.6875 - auc: 0.9376 - loss: 0.6963 - precision: 0.7586 - recall: 0.6875"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 329ms/step - accuracy: 0.6875 - auc: 0.9376 - loss: 0.6963 - precision: 0.7586 - recall: 0.6875 - val_accuracy: 0.6339 - val_auc: 0.8590 - val_loss: 1.0941 - val_precision: 0.6685 - val_recall: 0.5312 - learning_rate: 7.0011e-05\n","Epoch 17/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6778 - auc: 0.9117 - loss: 0.8566 - precision: 0.7359 - recall: 0.6301"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.6780 - auc: 0.9119 - loss: 0.8555 - precision: 0.7359 - recall: 0.6301 - val_accuracy: 0.6384 - val_auc: 0.8596 - val_loss: 1.1044 - val_precision: 0.6649 - val_recall: 0.5491 - learning_rate: 7.0011e-05\n","Epoch 18/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 339ms/step - accuracy: 0.5938 - auc: 0.8907 - loss: 0.9523 - precision: 0.6923 - recall: 0.5625 - val_accuracy: 0.6384 - val_auc: 0.8596 - val_loss: 1.1046 - val_precision: 0.6667 - val_recall: 0.5536 - learning_rate: 3.5005e-05\n","Epoch 19/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.6781 - auc: 0.9161 - loss: 0.8195 - precision: 0.7456 - recall: 0.6156 - val_accuracy: 0.6161 - val_auc: 0.8597 - val_loss: 1.1112 - val_precision: 0.6796 - val_recall: 0.5491 - learning_rate: 3.5005e-05\n","Epoch 20/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 347ms/step - accuracy: 0.7500 - auc: 0.9413 - loss: 0.6710 - precision: 0.7600 - recall: 0.5938 - val_accuracy: 0.6205 - val_auc: 0.8595 - val_loss: 1.1126 - val_precision: 0.6796 - val_recall: 0.5491 - learning_rate: 3.5005e-05\n","Epoch 21/30\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.7195 - auc: 0.9253 - loss: 0.7698 - precision: 0.7561 - recall: 0.6618 - val_accuracy: 0.6161 - val_auc: 0.8596 - val_loss: 1.1177 - val_precision: 0.6703 - val_recall: 0.5536 - learning_rate: 1.7503e-05\n","Training complete in 1398.62 seconds\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Evaluating model on test set...\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 12s/step - accuracy: 0.5356 - auc: 0.8105 - loss: 1.2843 - precision: 0.6292 - recall: 0.4959\n","Test accuracy: 0.6429\n","Test loss: 1.0124\n","Test precision: 0.7090\n","Test recall: 0.5982\n","Test AUC: 0.8787\n","F1 Score (approximated): 0.6489\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","        acne       0.80      0.36      0.49        45\n","       eksim       0.51      0.49      0.50        45\n","      herpes       0.78      0.64      0.71        45\n","        panu       0.68      0.89      0.77        45\n","     rosacea       0.57      0.84      0.68        44\n","\n","    accuracy                           0.64       224\n","   macro avg       0.67      0.64      0.63       224\n","weighted avg       0.67      0.64      0.63       224\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","Creating ensemble model...\n","Training ensemble member 1 with MobileNetV2...\n","Epoch 1/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.2832 - loss: 2.0956"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 8s/step - accuracy: 0.2855 - loss: 2.0880 - val_accuracy: 0.3259 - val_loss: 2.0844 - learning_rate: 1.0000e-04\n","Epoch 2/15\n","\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:09\u001b[0m 8s/step - accuracy: 0.2812 - loss: 1.5179"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self._interrupted_warning()\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.2812 - loss: 1.5179 - val_accuracy: 0.3214 - val_loss: 2.0962 - learning_rate: 1.0000e-04\n","Epoch 3/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.5471 - loss: 1.2770"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 9s/step - accuracy: 0.5481 - loss: 1.2740 - val_accuracy: 0.3482 - val_loss: 2.1147 - learning_rate: 1.0000e-04\n","Epoch 4/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 353ms/step - accuracy: 0.7500 - loss: 0.8330 - val_accuracy: 0.3482 - val_loss: 2.1212 - learning_rate: 1.0000e-04\n","Epoch 5/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 9s/step - accuracy: 0.6805 - loss: 0.8720 - val_accuracy: 0.3348 - val_loss: 2.0728 - learning_rate: 5.0000e-05\n","Epoch 6/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 289ms/step - accuracy: 0.7188 - loss: 0.7359 - val_accuracy: 0.3393 - val_loss: 2.0787 - learning_rate: 5.0000e-05\n","Epoch 7/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 8s/step - accuracy: 0.7160 - loss: 0.8037 - val_accuracy: 0.3304 - val_loss: 2.2522 - learning_rate: 5.0000e-05\n","Epoch 8/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 348ms/step - accuracy: 0.8125 - loss: 0.5137 - val_accuracy: 0.3304 - val_loss: 2.2575 - learning_rate: 5.0000e-05\n","Epoch 9/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.7668 - loss: 0.6061"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 10s/step - accuracy: 0.7667 - loss: 0.6075 - val_accuracy: 0.3527 - val_loss: 2.3488 - learning_rate: 2.5000e-05\n","Epoch 10/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 310ms/step - accuracy: 0.7500 - loss: 0.5385 - val_accuracy: 0.3527 - val_loss: 2.3531 - learning_rate: 2.5000e-05\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Training ensemble member 2 with ResNet50...\n","Epoch 1/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26s/step - accuracy: 0.3828 - loss: 1.7691 "]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m983s\u001b[0m 28s/step - accuracy: 0.3866 - loss: 1.7568 - val_accuracy: 0.2009 - val_loss: 1.9077 - learning_rate: 1.0000e-04\n","Epoch 2/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.5625 - loss: 1.1112 - val_accuracy: 0.2009 - val_loss: 1.8976 - learning_rate: 1.0000e-04\n","Epoch 3/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m960s\u001b[0m 28s/step - accuracy: 0.7895 - loss: 0.5703 - val_accuracy: 0.2009 - val_loss: 2.9513 - learning_rate: 1.0000e-04\n","Epoch 4/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.3035 - val_accuracy: 0.2009 - val_loss: 2.9648 - learning_rate: 1.0000e-04\n","Epoch 5/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m955s\u001b[0m 28s/step - accuracy: 0.8951 - loss: 0.3100 - val_accuracy: 0.2009 - val_loss: 3.6296 - learning_rate: 1.0000e-04\n","Epoch 6/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.8125 - loss: 0.3833 - val_accuracy: 0.2009 - val_loss: 3.6318 - learning_rate: 5.0000e-05\n","Epoch 7/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m922s\u001b[0m 28s/step - accuracy: 0.9130 - loss: 0.2558 - val_accuracy: 0.2009 - val_loss: 4.1369 - learning_rate: 5.0000e-05\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Training ensemble member 3 with EfficientNetB0...\n","Epoch 1/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - accuracy: 0.2346 - loss: 2.1966 "]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 12s/step - accuracy: 0.2361 - loss: 2.1912 - val_accuracy: 0.2009 - val_loss: 1.6350 - learning_rate: 1.0000e-04\n","Epoch 2/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 876ms/step - accuracy: 0.5938 - loss: 1.2936 - val_accuracy: 0.2009 - val_loss: 1.6345 - learning_rate: 1.0000e-04\n","Epoch 3/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 13s/step - accuracy: 0.4693 - loss: 1.4417 - val_accuracy: 0.1964 - val_loss: 1.6481 - learning_rate: 1.0000e-04\n","Epoch 4/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 998ms/step - accuracy: 0.5312 - loss: 1.2467 - val_accuracy: 0.1964 - val_loss: 1.6505 - learning_rate: 1.0000e-04\n","Epoch 5/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 11s/step - accuracy: 0.5995 - loss: 1.0530 - val_accuracy: 0.1964 - val_loss: 1.7091 - learning_rate: 1.0000e-04\n","Epoch 6/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 964ms/step - accuracy: 0.7500 - loss: 0.8389 - val_accuracy: 0.1964 - val_loss: 1.7110 - learning_rate: 5.0000e-05\n","Epoch 7/15\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 13s/step - accuracy: 0.6306 - loss: 1.0235 - val_accuracy: 0.1920 - val_loss: 1.7268 - learning_rate: 5.0000e-05\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Evaluating ensemble model...\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6s/step\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step\n","Ensemble accuracy: 0.3170\n","Ensemble Classification Report:\n","              precision    recall  f1-score   support\n","\n","        acne       0.25      0.04      0.08        45\n","       eksim       0.38      0.13      0.20        45\n","      herpes       0.00      0.00      0.00        45\n","        panu       0.30      0.78      0.44        45\n","     rosacea       0.33      0.64      0.43        44\n","\n","    accuracy                           0.32       224\n","   macro avg       0.25      0.32      0.23       224\n","weighted avg       0.25      0.32      0.23       224\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Final model saved to /content/drive/MyDrive/MINI_PROJECT/Results/final_skin_disease_model.h5\n","Model training and evaluation complete. All results saved to the Results directory.\n"]}],"source":["# Import necessary libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.applications import MobileNetV2, ResNet50, EfficientNetB0\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n","import seaborn as sns\n","from sklearn.utils.class_weight import compute_class_weight\n","!pip install keras-tuner\n","import keras_tuner as kt\n","import time\n","from datetime import datetime\n","\n","# # Connect to Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# Set correct paths to your dataset\n","base_dir = '/content/drive/MyDrive/MINI_PROJECT'\n","data_dir = os.path.join(base_dir, 'data')\n","train_dir = os.path.join(data_dir, 'train')\n","val_dir = os.path.join(data_dir, 'val')\n","test_dir = os.path.join(data_dir, 'test')\n","\n","# Create a directory for saving results\n","results_dir = os.path.join(base_dir, 'Results')\n","os.makedirs(results_dir, exist_ok=True)\n","\n","# Create a log file for tracking results\n","log_file_path = os.path.join(results_dir, 'training_log.txt')\n","def log_message(message):\n","    with open(log_file_path, 'a') as log_file:\n","        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","        log_file.write(f\"[{timestamp}] {message}\\n\")\n","    print(message)\n","\n","log_message(f\"Starting skin disease classification project\")\n","log_message(f\"Train directory: {train_dir}\")\n","log_message(f\"Validation directory: {val_dir}\")\n","log_message(f\"Test directory: {test_dir}\")\n","\n","# Filter out hidden directories and get actual class names\n","train_classes = [d for d in os.listdir(train_dir) if not d.startswith('.') and os.path.isdir(os.path.join(train_dir, d))]\n","val_classes = [d for d in os.listdir(val_dir) if not d.startswith('.') and os.path.isdir(os.path.join(val_dir, d))]\n","test_classes = [d for d in os.listdir(test_dir) if not d.startswith('.') and os.path.isdir(os.path.join(test_dir, d))]\n","\n","# Use the common classes across all directories\n","skin_classes = sorted(list(set(train_classes).intersection(set(val_classes)).intersection(set(test_classes))))\n","log_message(f\"Classes used in model: {skin_classes}\")\n","log_message(f\"Number of classes: {len(skin_classes)}\")\n","\n","# Count images in each split\n","def count_images(directory, class_list):\n","    total = 0\n","    class_counts = {}\n","    for class_name in class_list:\n","        class_dir = os.path.join(directory, class_name)\n","        if os.path.isdir(class_dir):\n","            count = len([f for f in os.listdir(class_dir) if not f.startswith('.')])\n","            class_counts[class_name] = count\n","            total += count\n","    return total, class_counts\n","\n","train_total, train_counts = count_images(train_dir, skin_classes)\n","val_total, val_counts = count_images(val_dir, skin_classes)\n","test_total, test_counts = count_images(test_dir, skin_classes)\n","\n","log_message(f\"Training images per class: {train_counts}\")\n","log_message(f\"Validation images per class: {val_counts}\")\n","log_message(f\"Test images per class: {test_counts}\")\n","\n","# Calculate class weights to handle imbalanced data\n","class_weights = {}\n","labels = []\n","for class_name in skin_classes:\n","    for _ in range(train_counts[class_name]):\n","        labels.append(skin_classes.index(class_name))\n","\n","labels = np.array(labels)\n","weight = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n","for i, class_name in enumerate(skin_classes):\n","    class_weights[i] = weight[i]\n","\n","log_message(f\"Class weights for training: {class_weights}\")\n","\n","# Visualize class distribution with better styling\n","plt.figure(figsize=(12, 6))\n","train_bars = plt.bar(train_counts.keys(), train_counts.values(), alpha=0.7, label='Training')\n","plt.bar(val_counts.keys(), [val_counts[k] for k in train_counts.keys()], alpha=0.7, bottom=[train_counts[k] for k in train_counts.keys()], label='Validation')\n","plt.xticks(rotation=45, ha='right')\n","plt.title('Class Distribution in Dataset', fontsize=16)\n","plt.xlabel('Class', fontsize=14)\n","plt.ylabel('Number of Images', fontsize=14)\n","plt.legend()\n","plt.tight_layout()\n","plt.savefig(os.path.join(results_dir, 'class_distribution.png'), dpi=300)\n","plt.close()\n","\n","# Set image size and batch size\n","img_height, img_width = 224, 224\n","batch_size = 32\n","\n","# Define improved data augmentation for training\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    vertical_flip=False,  # For skin images, vertical flip might not make sense\n","    fill_mode='nearest',\n","    brightness_range=[0.8, 1.2]  # Add brightness variation\n",")\n","\n","# Just rescaling for validation and test\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Create data generators\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True,\n","    classes=skin_classes\n",")\n","\n","validation_generator = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False,\n","    classes=skin_classes\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False,\n","    classes=skin_classes\n",")\n","\n","# Get class indices and prepare for later evaluation\n","class_indices = train_generator.class_indices\n","class_names = list(class_indices.keys())\n","num_classes = len(class_names)\n","log_message(f\"Class indices: {class_indices}\")\n","\n","# Show some sample images with improved visualization\n","def show_batch(image_batch, label_batch, save_path=None):\n","    plt.figure(figsize=(12, 12))\n","    for i in range(min(16, len(image_batch))):\n","        ax = plt.subplot(4, 4, i + 1)\n","        plt.imshow(image_batch[i])\n","        class_idx = np.argmax(label_batch[i])\n","        plt.title(f\"{class_names[class_idx]}\", fontsize=12)\n","        plt.axis(\"off\")\n","    plt.tight_layout()\n","    if save_path:\n","        plt.savefig(save_path, dpi=300)\n","        plt.close()\n","    else:\n","        plt.show()\n","\n","# Get a batch of images and save to results folder\n","images, labels = next(train_generator)\n","show_batch(images, labels, os.path.join(results_dir, 'sample_training_images.png'))\n","\n","# Define a function to build model for hyperparameter tuning\n","def build_model(hp):\n","    # Choose a base model\n","    base_model_choice = hp.Choice('base_model', ['MobileNetV2', 'ResNet50', 'EfficientNetB0'])\n","\n","    if base_model_choice == 'MobileNetV2':\n","        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n","    elif base_model_choice == 'ResNet50':\n","        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n","    else:  # EfficientNetB0\n","        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n","\n","    # Freeze or unfreeze base model\n","    base_model.trainable = hp.Boolean('trainable_base', default=False)\n","\n","    # Create model\n","    model = Sequential([\n","        base_model,\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        Dense(\n","            units=hp.Int('dense_units', min_value=128, max_value=512, step=64),\n","            activation=hp.Choice('dense_activation', ['relu', 'selu'])\n","        ),\n","        BatchNormalization(),\n","        Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","\n","    # Compile model\n","    model.compile(\n","        optimizer=Adam(\n","            learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-3, sampling='log')\n","        ),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy',\n","                tf.keras.metrics.Precision(name='precision'),\n","                tf.keras.metrics.Recall(name='recall'),\n","                tf.keras.metrics.AUC(name='auc')]\n","    )\n","\n","    return model\n","\n","# Implement hyperparameter tuning\n","log_message(\"Starting hyperparameter tuning...\")\n","tuner = kt.Hyperband(\n","    build_model,\n","    objective='val_accuracy',\n","    max_epochs=15,\n","    factor=3,\n","    directory=os.path.join(results_dir, 'tuner'),\n","    project_name='skin_disease_classifier'\n",")\n","\n","# Define early stopping callback for tuning\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    restore_best_weights=True\n",")\n","\n","# Calculate steps correctly\n","steps_per_epoch = train_generator.samples // batch_size\n","validation_steps = validation_generator.samples // batch_size\n","steps_per_epoch = max(1, steps_per_epoch)\n","validation_steps = max(1, validation_steps)\n","\n","log_message(f\"Steps per epoch: {steps_per_epoch}\")\n","log_message(f\"Validation steps: {validation_steps}\")\n","\n","# Start the search\n","tuner.search(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=15,\n","    validation_data=validation_generator,\n","    validation_steps=validation_steps,\n","    callbacks=[early_stopping],\n","    class_weight=class_weights\n",")\n","\n","# Get the best hyperparameters\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","log_message(f\"Best hyperparameters: {best_hps.values}\")\n","\n","# Build the best model\n","best_model = tuner.hypermodel.build(best_hps)\n","log_message(\"Best model architecture:\")\n","best_model.summary(print_fn=lambda x: log_message(x))\n","\n","# Set up callbacks for final training\n","model_checkpoint_path = os.path.join(results_dir, 'best_model.h5')\n","callbacks = [\n","    EarlyStopping(\n","        monitor='val_loss',\n","        patience=10,\n","        restore_best_weights=True\n","    ),\n","    ModelCheckpoint(\n","        filepath=model_checkpoint_path,\n","        save_best_only=True,\n","        monitor='val_accuracy',\n","        mode='max'\n","    ),\n","    ReduceLROnPlateau(\n","        monitor='val_loss',\n","        factor=0.5,\n","        patience=3,\n","        min_lr=1e-6\n","    )\n","]\n","\n","# Train the best model for more epochs\n","log_message(\"Training the best model...\")\n","start_time = time.time()\n","history = best_model.fit(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=30,\n","    validation_data=validation_generator,\n","    validation_steps=validation_steps,\n","    callbacks=callbacks,\n","    class_weight=class_weights\n",")\n","training_time = time.time() - start_time\n","log_message(f\"Training complete in {training_time:.2f} seconds\")\n","\n","# Plot training history with improved visualization\n","def plot_training_history(history, save_path_prefix):\n","    metrics = ['accuracy', 'loss', 'precision', 'recall', 'auc']\n","    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n","    axes = axes.flatten()\n","\n","    for i, metric in enumerate(metrics):\n","        if i < len(axes) and f'{metric}' in history.history:\n","            ax = axes[i]\n","            ax.plot(history.history[f'{metric}'], label=f'Training {metric}')\n","            ax.plot(history.history[f'val_{metric}'], label=f'Validation {metric}')\n","            ax.set_title(f'{metric.capitalize()} over Epochs', fontsize=14)\n","            ax.set_xlabel('Epoch', fontsize=12)\n","            ax.set_ylabel(metric.capitalize(), fontsize=12)\n","            ax.legend()\n","            ax.grid(True, linestyle='--', alpha=0.7)\n","\n","    plt.tight_layout()\n","    plt.savefig(f\"{save_path_prefix}_metrics.png\", dpi=300)\n","    plt.close()\n","\n","    # Create a separate learning curve plot\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['accuracy'], label='Training Accuracy')\n","    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","    plt.title('Model Accuracy', fontsize=14)\n","    plt.xlabel('Epoch', fontsize=12)\n","    plt.ylabel('Accuracy', fontsize=12)\n","    plt.legend()\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title('Model Loss', fontsize=14)\n","    plt.xlabel('Epoch', fontsize=12)\n","    plt.ylabel('Loss', fontsize=12)\n","    plt.legend()\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    plt.tight_layout()\n","    plt.savefig(f\"{save_path_prefix}_learning_curve.png\", dpi=300)\n","    plt.close()\n","\n","plot_training_history(history, os.path.join(results_dir, 'training_history'))\n","\n","# Load the best model (the one saved during training)\n","best_model = load_model(model_checkpoint_path)\n","\n","# Comprehensive evaluation on test set\n","test_steps = max(1, test_generator.samples // batch_size)\n","log_message(\"Evaluating model on test set...\")\n","test_loss, test_acc, test_precision, test_recall, test_auc = best_model.evaluate(test_generator, steps=test_steps)\n","log_message(f\"Test accuracy: {test_acc:.4f}\")\n","log_message(f\"Test loss: {test_loss:.4f}\")\n","log_message(f\"Test precision: {test_precision:.4f}\")\n","log_message(f\"Test recall: {test_recall:.4f}\")\n","log_message(f\"Test AUC: {test_auc:.4f}\")\n","log_message(f\"F1 Score (approximated): {2 * (test_precision * test_recall) / (test_precision + test_recall):.4f}\")\n","\n","# Make predictions on test set with appropriate resetting\n","test_generator.reset()\n","y_pred_probs = best_model.predict(test_generator, steps=test_steps)\n","y_pred_classes = np.argmax(y_pred_probs, axis=1)\n","\n","# Get true labels (ensuring we have the correct number)\n","y_true = test_generator.classes[:len(y_pred_classes)]\n","\n","# Generate detailed classification report\n","class_report = classification_report(y_true, y_pred_classes, target_names=class_names, output_dict=True)\n","log_message(\"Classification Report:\\n\" + classification_report(y_true, y_pred_classes, target_names=class_names))\n","\n","# Save classification report as CSV\n","class_report_df = pd.DataFrame(class_report).transpose()\n","class_report_df.to_csv(os.path.join(results_dir, 'classification_report.csv'))\n","\n","# Plot confusion matrix with improved styling\n","plt.figure(figsize=(10, 8))\n","cm = confusion_matrix(y_true, y_pred_classes)\n","cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","sns.heatmap(cm_normalized, annot=cm, fmt='d', cmap='Blues',\n","            xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 12})\n","plt.title('Confusion Matrix', fontsize=16)\n","plt.ylabel('True Label', fontsize=14)\n","plt.xlabel('Predicted Label', fontsize=14)\n","plt.tight_layout()\n","plt.savefig(os.path.join(results_dir, 'confusion_matrix.png'), dpi=300)\n","plt.close()\n","\n","# Plot ROC curves\n","plt.figure(figsize=(12, 10))\n","for i, class_name in enumerate(class_names):\n","    # Binarize the output for current class\n","    y_true_bin = (y_true == i).astype(int)\n","    y_score = y_pred_probs[:, i]\n","\n","    # Compute ROC\n","    fpr, tpr, _ = roc_curve(y_true_bin, y_score)\n","    roc_auc = auc(fpr, tpr)\n","\n","    # Plot ROC curve\n","    plt.plot(fpr, tpr, lw=2, label=f'{class_name} (AUC = {roc_auc:.2f})')\n","\n","plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate', fontsize=14)\n","plt.ylabel('True Positive Rate', fontsize=14)\n","plt.title('ROC Curves for Each Class', fontsize=16)\n","plt.legend(loc=\"lower right\")\n","plt.grid(True, linestyle='--', alpha=0.7)\n","plt.tight_layout()\n","plt.savefig(os.path.join(results_dir, 'roc_curves.png'), dpi=300)\n","plt.close()\n","\n","# Plot Precision-Recall curves\n","plt.figure(figsize=(12, 10))\n","for i, class_name in enumerate(class_names):\n","    # Binarize the output for current class\n","    y_true_bin = (y_true == i).astype(int)\n","    y_score = y_pred_probs[:, i]\n","\n","    # Compute PR curve\n","    precision, recall, _ = precision_recall_curve(y_true_bin, y_score)\n","    avg_precision = average_precision_score(y_true_bin, y_score)\n","\n","    # Plot PR curve\n","    plt.plot(recall, precision, lw=2, label=f'{class_name} (AP = {avg_precision:.2f})')\n","\n","plt.xlabel('Recall', fontsize=14)\n","plt.ylabel('Precision', fontsize=14)\n","plt.title('Precision-Recall Curves for Each Class', fontsize=16)\n","plt.legend(loc=\"best\")\n","plt.grid(True, linestyle='--', alpha=0.7)\n","plt.tight_layout()\n","plt.savefig(os.path.join(results_dir, 'precision_recall_curves.png'), dpi=300)\n","plt.close()\n","\n","# Create a function to visualize correctly and incorrectly classified samples\n","def visualize_predictions(model, generator, class_names, num_samples=4, save_path=None):\n","    # Get a batch of test images\n","    generator.reset()\n","    batch_images, batch_labels = next(generator)\n","\n","    # Make predictions\n","    predictions = model.predict(batch_images)\n","\n","    # Create a figure with two rows: correct and incorrect predictions\n","    fig, axes = plt.subplots(2, num_samples, figsize=(16, 8))\n","\n","    # Find correct and incorrect predictions\n","    pred_classes = np.argmax(predictions, axis=1)\n","    true_classes = np.argmax(batch_labels, axis=1)\n","\n","    correct_indices = np.where(pred_classes == true_classes)[0]\n","    incorrect_indices = np.where(pred_classes != true_classes)[0]\n","\n","    # Plot correct predictions\n","    correct_title = \"Correctly Classified Examples\"\n","    plt.figtext(0.5, 0.95, correct_title, ha='center', va='center', fontsize=16, fontweight='bold')\n","\n","    for i in range(num_samples):\n","        if i < len(correct_indices):\n","            idx = correct_indices[i]\n","            ax = axes[0, i]\n","            ax.imshow(batch_images[idx])\n","            true_class = class_names[true_classes[idx]]\n","            pred_class = class_names[pred_classes[idx]]\n","            pred_prob = np.max(predictions[idx]) * 100\n","            ax.set_title(f\"True: {true_class}\\nPred: {pred_class}\\nConf: {pred_prob:.1f}%\", fontsize=10)\n","            ax.axis('off')\n","        else:\n","            axes[0, i].axis('off')\n","\n","    # Plot incorrect predictions\n","    incorrect_title = \"Misclassified Examples\"\n","    plt.figtext(0.5, 0.48, incorrect_title, ha='center', va='center', fontsize=16, fontweight='bold')\n","\n","    for i in range(num_samples):\n","        if i < len(incorrect_indices):\n","            idx = incorrect_indices[i]\n","            ax = axes[1, i]\n","            ax.imshow(batch_images[idx])\n","            true_class = class_names[true_classes[idx]]\n","            pred_class = class_names[pred_classes[idx]]\n","            pred_prob = predictions[idx][pred_classes[idx]] * 100\n","            ax.set_title(f\"True: {true_class}\\nPred: {pred_class}\\nConf: {pred_prob:.1f}%\", fontsize=10)\n","            ax.axis('off')\n","        else:\n","            axes[1, i].axis('off')\n","\n","    plt.tight_layout(rect=[0, 0, 1, 0.95])\n","    if save_path:\n","        plt.savefig(save_path, dpi=300)\n","        plt.close()\n","    else:\n","        plt.show()\n","\n","# Visualize model predictions\n","visualize_predictions(best_model, test_generator, class_names,\n","                     save_path=os.path.join(results_dir, 'prediction_examples.png'))\n","\n","# Create an ensemble model (optional)\n","def create_ensemble():\n","    log_message(\"Creating ensemble model...\")\n","    # Define different base models for ensemble\n","    base_models = ['MobileNetV2', 'ResNet50', 'EfficientNetB0']\n","    ensemble_models = []\n","\n","    for i, base_name in enumerate(base_models):\n","        if base_name == 'MobileNetV2':\n","            base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n","        elif base_name == 'ResNet50':\n","            base = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n","        else:  # EfficientNetB0\n","            base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n","\n","        # Create model\n","        model = Sequential([\n","            base,\n","            tf.keras.layers.GlobalAveragePooling2D(),\n","            Dense(256, activation='relu'),\n","            BatchNormalization(),\n","            Dropout(0.3),\n","            Dense(num_classes, activation='softmax')\n","        ])\n","\n","        model.compile(\n","            optimizer=Adam(learning_rate=0.0001),\n","            loss='categorical_crossentropy',\n","            metrics=['accuracy']\n","        )\n","\n","        # Save path for this ensemble member\n","        model_path = os.path.join(results_dir, f'ensemble_model_{i}.h5')\n","\n","        # Set up callbacks\n","        callbacks = [\n","            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n","            ModelCheckpoint(filepath=model_path, save_best_only=True, monitor='val_accuracy'),\n","            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n","        ]\n","\n","        # Train model\n","        log_message(f\"Training ensemble member {i+1} with {base_name}...\")\n","        model.fit(\n","            train_generator,\n","            steps_per_epoch=steps_per_epoch,\n","            epochs=15,  # Fewer epochs for ensemble members\n","            validation_data=validation_generator,\n","            validation_steps=validation_steps,\n","            callbacks=callbacks,\n","            class_weight=class_weights\n","        )\n","\n","        # Load the best version of this model\n","        ensemble_models.append(load_model(model_path))\n","\n","    return ensemble_models\n","\n","# Optionally create and evaluate ensemble\n","if train_total > 500:  # Only create ensemble if enough training data\n","    ensemble_models = create_ensemble()\n","\n","    # Ensemble prediction function\n","    def ensemble_predict(models, generator, steps):\n","        generator.reset()\n","        predictions = None\n","\n","        # Get predictions from each model\n","        for model in models:\n","            model_preds = model.predict(generator, steps=steps)\n","            if predictions is None:\n","                predictions = model_preds\n","            else:\n","                predictions += model_preds\n","\n","        # Average predictions\n","        predictions /= len(models)\n","        return predictions\n","\n","    # Evaluate ensemble\n","    log_message(\"Evaluating ensemble model...\")\n","    ensemble_preds = ensemble_predict(ensemble_models, test_generator, test_steps)\n","    ensemble_classes = np.argmax(ensemble_preds, axis=1)\n","\n","    # Calculate accuracy\n","    ensemble_acc = np.mean(ensemble_classes == y_true)\n","    log_message(f\"Ensemble accuracy: {ensemble_acc:.4f}\")\n","\n","    # Generate classification report for ensemble\n","    log_message(\"Ensemble Classification Report:\\n\" +\n","                classification_report(y_true, ensemble_classes, target_names=class_names))\n","\n","# Function to predict on a single image (for deployment)\n","def predict_image(model, image_path, class_names):\n","    from tensorflow.keras.preprocessing import image\n","\n","    # Load and preprocess the image\n","    img = image.load_img(image_path, target_size=(img_height, img_width))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array = img_array / 255.0\n","\n","    # Make prediction\n","    prediction = model.predict(img_array)\n","    predicted_class = np.argmax(prediction, axis=1)[0]\n","\n","    # Print results\n","    print(f\"Predicted class: {class_names[predicted_class]}\")\n","    for i, class_name in enumerate(class_names):\n","        print(f\"{class_name}: {prediction[0][i]:.4f}\")\n","\n","    # Display the image with prediction\n","    plt.figure(figsize=(6, 6))\n","    plt.imshow(img)\n","    plt.title(f\"Predicted: {class_names[predicted_class]}\")\n","    plt.axis('off')\n","    plt.show()\n","\n","    return class_names[predicted_class], prediction[0]\n","\n","# Save model architecture and summary as text file\n","with open(os.path.join(results_dir, 'model_summary.txt'), 'w') as f:\n","    # Redirect summary to file\n","    best_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n","\n","    # Add model compilation details\n","    f.write(\"\\nModel Compilation Details:\\n\")\n","    f.write(f\"Optimizer: Adam\\n\")\n","    f.write(f\"Learning Rate: {best_hps.values['learning_rate']}\\n\")\n","    f.write(f\"Loss Function: categorical_crossentropy\\n\")\n","    f.write(f\"Metrics: accuracy, precision, recall, AUC\\n\")\n","\n","    # Add final performance metrics\n","    f.write(\"\\nFinal Performance Metrics:\\n\")\n","    f.write(f\"Test Accuracy: {test_acc:.4f}\\n\")\n","    f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n","    f.write(f\"Test Precision: {test_precision:.4f}\\n\")\n","    f.write(f\"Test Recall: {test_recall:.4f}\\n\")\n","    f.write(f\"Test AUC: {test_auc:.4f}\\n\")\n","    f.write(f\"F1 Score: {2 * (test_precision * test_recall) / (test_precision + test_recall):.4f}\\n\")\n","\n","# Save the final model\n","model_save_path = os.path.join(results_dir, 'final_skin_disease_model.h5')\n","best_model.save(model_save_path)\n","log_message(f\"Final model saved to {model_save_path}\")\n","\n","# Create a JSON file with class mapping for deployment\n","import json\n","class_mapping = {i: class_name for i, class_name in enumerate(class_names)}\n","with open(os.path.join(results_dir, 'class_mapping.json'), 'w') as f:\n","    json.dump(class_mapping, f)\n","\n","log_message(\"Model training and evaluation complete. All results saved to the Results directory.\")"]}]}